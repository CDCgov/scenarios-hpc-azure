# CFA Scenarios Azure HPC Acceleration

[Overview](#overview) |
[Quick Start](#quick-start) |
[Project Admins](#project-admins) |
[Fine Text and Disclaimers](#general-disclaimer)

## Overview

> [!IMPORTANT]
> This repository is under active development.
> Please look around, but we advise against working with this code until it has stabilized.

This repository is responsible for creating, visualizing, launching, and standardizing DynODE experiments.
An __experiment__ is the broadest categorization of an effort or goal, e.g. Fitting a particular time period in a specific way is an experiment.

When a user wants to launch an experiment, the individual run is called a __job__,
a job is broken down into a series of __tasks__ which represents the smallest
chunk of work handled by an individual Azure VM.
## Quick Start

After installing scenarios-hpc-azure into your `poetry` environment you should
have access to the scripts listed in `pyproject.toml` `[tool.poetry.scripts]` section.

Currently the two supported scripts are `create_experiment` and `launch_experiment`

These scripts will aid you in creating and launching your experiment and
are used as command line tools. Use the `-h` flag to get a brief description
on the expected input parameters to each script.

## Technical Details

Disclaimer: This library is not meant to be a catch-all way to parallelize DynODE
projects onto any hpc enviornment. On the backend, this project relies on
a library called [cfa-azure](https://github.com/CDCgov/cfa_azure)
which acts as a wrapper script around the base [Azure SDK](https://learn.microsoft.com/en-us/azure/developer/python/sdk/azure-sdk-overview). As a result of this dependency we do not offer any additional
guarantees not offered by `cfa-azure` in regards to its ability to work
out of the box with other Azure implementations. Every high performance
computing system will be different, even one Azure setup to the next may have
different authentication protocols or systems. This repository is public
out of an interest in transparency in how our system is orchistrated, but may
not be immediately useful to others. With all that being said let us
describe what it means for a DynODE model to be an experiment, and what an
experiment launching looks like.

A DynODE experiment is the broadest categorization of an effort or goal, if you
wish to fit a mechanistic compartmental model built with DynODE onto a specific
period of time, you may call that an experiment. An experiment must be nested
entirely in an `exp/` folder where the name of the experiment matches the name
of the directory within `exp/`. Lets create an example experiment called
`fitting_covid`, our experiment specific files would then be inside of the
repository under `exp/fitting_covid`. Here is an example directory structure.

```
exp/
├─ fitting_covid/
│  ├─ postprocessing_scripts/
│  │  ├─ combine_state_outputs.py
│  ├─ states/
│  │  ├─ CA/
│  │  │  ├─ config_global.json (readonly)
│  │  │  ├─ config_inference.json (readonly)
│  │  ├─ NY/
│  │  │  ├─ config_global.json (readonly)
│  │  │  ├─ config_inference.json (readonly)
│  │  ├─ TX/
│  │  │  ├─ config_global.json (readonly)
│  │  │  ├─ config_inference.json (readonly)
│  ├─ template_configs/
│  │  ├─ config_global.json
│  │  ├─ config_inference.json
│  ├─ misc_experiment_utils.py
│  ├─ run_task.py
secrets/
├─ azure_authentication_config.toml
Dockerfile
poetry.lock
pyproject.toml

```
The actual modeling, reading, writing, and processing, is all kicked off
by the `run_task.py` script.

Each directory within `states/` will be launched
as a single Azure task, all under the same Azure job.

Configuration files and
directories within `states/` are programmatically generated by the
`create_experiment` script, using the files
found within `exp/fitting_covid/template_configs` as a base. The reason why
all json files within `states/` are read-only is to avoid undocumented
one-off changes to individual states which can be exceedingly hard to track down.
Any state-specific changes should be written in code within a commited
experiment_creator script.

Files within `postprocessing_scripts/` are often scripts that run after
every state is finished modeling. Their responsibilities may include things like
visualization, data collation, or writing to other databases.

The `azure_authentication_config.toml` within the `secrets/` directory
is meant to provide all the necessary information to authenticate
a user onto the Azure system, either by managed identity, service principal,
or user identity. The implementation details surrounding this system are
all internal to [cfa-azure](https://github.com/CDCgov/cfa_azure).

Lastly, the `Dockerfile`, `poetry.lock`, and `pyproject.toml` are files that
containerize the experiment, and manage its python version and dependencies.
This package is often included as a developer dependency within
`pyproject.toml`. This is because it is needed to launch the job, but unless
jobs are launching other jobs (which they should not except in very special
circumstances), this code is not needed within an Azure VM.

The intended goal for the `create_experiment` script is to provide an easy
way for users to programatically copy over their template configuration files
to each of the states they hope to model. The `launch_experiment` script
does a number of important tasks needed to launch onto Azure. Firstly it
containerizes the python version, dependencies, and any other
files the user wants in their Docker image. Then it uploads that
image to the Azure Container Registry (ACR) where the VM's can access it. Next
it uploads the experiment directory to a blob storage in a particular location.
The reason files are uploaded and not included in the image is to reduce
image rebuilds and reuploads every time a small change is made to `run_task.py`.

Experiments are uploaded to a location on blob based on the experiment name and
the id of the job being launched. In this case if the user wants to call their
job `fitting_job_1` the `exp/fitting_covid` directory would be
uploaded to `input_blob/exp/fitting_covid/fitting_job_1`. Thus, a user may
later return to the `input_blob/exp/fitting_covid` directory and find all
relevant files to any of their past jobs.

Once the `launch_experiment` script has uploaded the image to the ACR, and the
`exp/fitting_covid` directory to the input blob storage. It will then
send instructions to Azure Batch to spin up a pool of VMs with a
specified number of CPUs (default 4) and to create 1 task per
state within `exp/fitting_covid/states/`, passing that state's name to
`run_task.py` via command line arguments. From there your `run_task.py` script
takes over control within the Azure VM and does the work for that state.

## Project Admins
Thomas Hladish, Lead Data Scientist, utx5@cdc.gov, CDC/IOD/ORR/CFA

Ariel Shurygin, Data Scientist, uva5@cdc.gov, CDC/IOD/ORR/CFA

Ed Baskerville, Data Scientist, ah20@cdc.gov, CDC/IOD/ORR/CFA (Contract)

## General Disclaimer
This repository was created for use by CDC programs to collaborate on public health related projects in support of the [CDC mission](https://www.cdc.gov/about/organization/mission.htm).  GitHub is not hosted by the CDC, but is a third party website used by CDC and its partners to share information and collaborate on software. CDC use of GitHub does not imply an endorsement of any one particular service, product, or enterprise.

## Public Domain Standard Notice
This repository constitutes a work of the United States Government and is not
subject to domestic copyright protection under 17 USC § 105. This repository is in
the public domain within the United States, and copyright and related rights in
the work worldwide are waived through the [CC0 1.0 Universal public domain dedication](https://creativecommons.org/publicdomain/zero/1.0/).
All contributions to this repository will be released under the CC0 dedication. By
submitting a pull request you are agreeing to comply with this waiver of
copyright interest.

## License Standard Notice
This repository is licensed under ASL v2 or later.

This source code in this repository is free: you can redistribute it and/or modify it under
the terms of the Apache Software License version 2, or (at your option) any
later version.

This source code in this repository is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE. See the Apache Software License for more details.

You should have received a copy of the Apache Software License along with this
program. If not, see http://www.apache.org/licenses/LICENSE-2.0.html

The source code forked from other open source projects will inherit its license.

## Privacy Standard Notice
This repository contains only non-sensitive, publicly available data and
information. All material and community participation is covered by the
[Disclaimer](https://github.com/CDCgov/template/blob/master/DISCLAIMER.md)
and [Code of Conduct](https://github.com/CDCgov/template/blob/master/code-of-conduct.md).
For more information about CDC's privacy policy, please visit [http://www.cdc.gov/other/privacy.html](https://www.cdc.gov/other/privacy.html).

## Contributing Standard Notice
Anyone is encouraged to contribute to the repository by [forking](https://help.github.com/articles/fork-a-repo)
and submitting a pull request. (If you are new to GitHub, you might start with a
[basic tutorial](https://help.github.com/articles/set-up-git).) By contributing
to this project, you grant a world-wide, royalty-free, perpetual, irrevocable,
non-exclusive, transferable license to all users under the terms of the
[Apache Software License v2](http://www.apache.org/licenses/LICENSE-2.0.html) or
later.

All comments, messages, pull requests, and other submissions received through
CDC including this GitHub page may be subject to applicable federal law, including but not limited to the Federal Records Act, and may be archived. Learn more at [http://www.cdc.gov/other/privacy.html](http://www.cdc.gov/other/privacy.html).

## Records Management Standard Notice
This repository is not a source of government records but is a copy to increase
collaboration and collaborative potential. All government records will be
published through the [CDC web site](http://www.cdc.gov).

## Additional Standard Notices
Please refer to [CDC's Template Repository](https://github.com/CDCgov/template)
for more information about [contributing to this repository](https://github.com/CDCgov/template/blob/master/CONTRIBUTING.md),
[public domain notices and disclaimers](https://github.com/CDCgov/template/blob/master/DISCLAIMER.md),
and [code of conduct](https://github.com/CDCgov/template/blob/master/code-of-conduct.md).
